{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ae8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from torchmetrics import Metric\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f59237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMAE(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state(\"nmae\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        assert preds.shape == target.shape\n",
    "        nmae = torch.sum(torch.abs(target-preds) / (torch.abs(target)))\n",
    "        n_obs = target.numel()\n",
    "        self.nmae += nmae\n",
    "        self.total += n_obs\n",
    "    def compute(self):\n",
    "        return self.nmae / self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a15711e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1592/1592 [00:02<00:00, 627.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 460/460 [00:00<00:00, 514.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 523.72it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessing_train_imgs = glob(\"D:/DACON_GROWTH/PREPROCESSING-TRAIN_224/*\")\n",
    "preprocessing_test_imgs = glob(\"D:/DACON_GROWTH/PREPROCESSING-TEST_224/*\")\n",
    "augmetation_imgs = glob(\"D:/DACON_GROWTH/AUGMENTATION/SIZE224/*\")\n",
    "\n",
    "outlier_imgs = []\n",
    "outlier_path = []\n",
    "train_path = []\n",
    "train_imgs = []\n",
    "for path in tqdm(preprocessing_train_imgs):\n",
    "    img_file = os.path.basename(path)\n",
    "    img_name = img_file.split(\".\")[0]\n",
    "    case = img_name.split(\"_\")[0]\n",
    "    if case in [\"CASE59\", \"CASE11\", \"CASE12\", \"CASE13\", \"CASE14\"]:\n",
    "        continue\n",
    "    elif img_name in [\"CASE05_21\", \"CASE10_41\", \"CASE45_16\", \"CASE45_17\",\n",
    "                     \"CASE73_04\", \"CASE73_10\", \"CASE73_11\", \"CASE73_14\"]:        \n",
    "        continue\n",
    "    elif case in [\"CASE16\", \"CASE22\", \"CASE23\"]:\n",
    "        continue\n",
    "    else:\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        train_path.append(path)\n",
    "        train_imgs.append(img)\n",
    "        \n",
    "test_path = []\n",
    "test_imgs = []\n",
    "for path in tqdm(preprocessing_test_imgs):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    test_path.append(path)\n",
    "    test_imgs.append(img)\n",
    "\n",
    "augment_path = []\n",
    "augment_imgs = []\n",
    "for path in tqdm(augmetation_imgs):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    augment_path.append(path)\n",
    "    augment_imgs.append(img)\n",
    "    \n",
    "augment_path = augment_path + outlier_path\n",
    "augment_imgs = augment_imgs + outlier_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abb7797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validset_path, trainset_path  = train_test_split(train_path, train_size =0.078, shuffle=False)\n",
    "valid_imgset, train_imgset = train_test_split(train_imgs, train_size =0.078, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "46d82a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_dict[\"18:05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f4b2c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1592/1592 [00:22<00:00, 69.90it/s]\n"
     ]
    }
   ],
   "source": [
    "main_path = \"D:/DACON_GROWTH\"\n",
    "train_data = glob(main_path+\"/train/*/meta/*.csv\")\n",
    "train_label = glob(main_path+\"/train/*/*.csv\")\n",
    "test_data = glob(main_path+\"/test/meta/*.csv\")\n",
    "\n",
    "train_df = []\n",
    "for i in tqdm(train_data):\n",
    "    name = i.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    df = pd.read_csv(i)\n",
    "    df[\"이미지\"] = name\n",
    "    case = name.split(\"_\")[0]\n",
    "    label = pd.read_csv(f\"D:/DACON_GROWTH/train/{case}/label.csv\")\n",
    "    label_name = [i.split(\".\")[0] for i in label.img_name]\n",
    "    label.img_name = label_name\n",
    "    leaf_weight = label[label.img_name == name].leaf_weight.values[0]\n",
    "    df[\"무게\"] = leaf_weight\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    train_df.append(df)\n",
    "\n",
    "train_df = pd.concat(train_df, ignore_index=True)\n",
    "train_df[\"무게\"] = train_df[\"무게\"].apply(lambda x: 0.001 if x<0.001 else x)\n",
    "\n",
    "img2weight = {}\n",
    "for i in tqdm(train_df[\"이미지\"].unique()):\n",
    "    temp = train_df[train_df[\"이미지\"]==i]\n",
    "    weight = temp[\"무게\"].values[0]\n",
    "    img2weight[i] = weight\n",
    "    \n",
    "train_df[\"시간2\"] = train_df[\"시간\"].apply(lambda x: x.split(\" \")[-1])\n",
    "golden_time = ['17:40', '17:41', '17:42', '17:43', '17:44', '17:45', '17:46', '17:47', '17:48', '17:49', '17:50',\n",
    "               '17:51', '17:52', '17:53', '17:54', '17:55', '17:56', '17:57', '17:58', '17:59', '18:00', '18:01',\n",
    "               '18:02', '18:03', '18:04', '18:05']\n",
    "golden_dict ={}\n",
    "for e, i in enumerate(train_df[\"시간2\"].unique()):\n",
    "       golden_dict[i] = e\n",
    "train_df[\"순서\"] = train_df[\"시간2\"].apply(lambda x : golden_dict[x])\n",
    "\n",
    "train_df2 = train_df[(train_df[\"순서\"] > 894) & (train_df[\"순서\"] < 919)]\n",
    "\n",
    "train_dfx = train_df2.copy()\n",
    "train_dfx.drop(columns=[\"시간\", \"시간2\"], inplace=True)\n",
    "train_dfx.fillna(0., inplace=True)\n",
    "\n",
    "# img2data = {}\n",
    "# for i in tqdm(train_dfx['이미지'].unique()):\n",
    "#     temp = train_dfx[train_dfx[\"이미지\"]==i]\n",
    "#     temp.drop(columns = [\"무게\", \"이미지\"], inplace=True)\n",
    "#     img2data[i] = np.array(temp[[\"EC관측치\",'내부습도관측치', '외부습도관측치']].values, dtype=np.float32)\n",
    "    \n",
    "# test_df = []\n",
    "# for i in tqdm(test_data):\n",
    "#     name = i.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "#     df = pd.read_csv(i)\n",
    "#     df[\"이미지\"] = name\n",
    "#     df = df.replace([np.inf, -np.inf], np.nan)\n",
    "#     test_df.append(df)\n",
    "    \n",
    "# test_df = pd.concat(test_df, ignore_index=True)\n",
    "# test_df[\"시간2\"] = test_df[\"시간\"].apply(lambda x: x.split(\" \")[-1])\n",
    "# test_df[\"순서\"] = test_df[\"시간2\"].apply(lambda x : golden_dict[x])\n",
    "# test_df2 = test_df[(test_df[\"순서\"] > 894) & (test_df[\"순서\"] < 919)]\n",
    "\n",
    "# test_dfx = test_df2.copy()\n",
    "# test_dfx.drop(columns=[\"시간\", \"시간2\"], inplace=True)\n",
    "# test_dfx.fillna(0., inplace=True)\n",
    "\n",
    "# img2test = {}\n",
    "# for i in tqdm(test_dfx['이미지'].unique()):\n",
    "#     temp = test_dfx[test_dfx[\"이미지\"]==i]\n",
    "#     temp.drop(columns = \"이미지\", inplace=True)\n",
    "#     img2test[i] = np.array(temp[[\"EC관측치\",'내부습도관측치', '외부습도관측치']].values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c6224507",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['내부온도관측치', '외부온도관측치', '내부습도관측치', '외부습도관측치', 'CO2관측치', 'EC관측치',\n",
    "       '최근분무량', '화이트 LED동작강도', '레드 LED동작강도', '블루 LED동작강도', '냉방온도', '냉방부하',\n",
    "       '난방온도', '난방부하', '총추정광량', '백색광추정광량', '적색광추정광량', '청색광추정광량']\n",
    "train_feature = train_dfx[features]\n",
    "train_weight = train_dfx[\"무게\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f3519d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38208, 18)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8dcdfa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_DATASET(nn.Module):\n",
    "    def __init__(self, x, y):\n",
    "        super(DNN_DATASET, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out = self.x[idx]\n",
    "        target = self.y[idx]\n",
    "\n",
    "        return out, target\n",
    "    \n",
    "train_set = DNN_DATASET(train_feature.values, train_weight.values)\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=16, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0de760af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(18, 2)\n",
    "        self.out = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5523a235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\meta2\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:96: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN    loss : 73.77092 epoch : 0 \n",
      "TRAIN    loss : 72.36902 epoch : 1 \n",
      "TRAIN    loss : 72.14285 epoch : 2 \n",
      "TRAIN    loss : 71.98526 epoch : 3 \n",
      "TRAIN    loss : 71.86070 epoch : 4 \n",
      "TRAIN    loss : 71.77276 epoch : 5 \n",
      "TRAIN    loss : 71.69546 epoch : 6 \n",
      "TRAIN    loss : 71.62692 epoch : 7 \n",
      "TRAIN    loss : 71.54614 epoch : 8 \n",
      "TRAIN    loss : 71.47409 epoch : 9 \n",
      "TRAIN    loss : 71.43765 epoch : 10 \n",
      "TRAIN    loss : 71.38789 epoch : 11 \n",
      "TRAIN    loss : 71.36752 epoch : 12 \n",
      "TRAIN    loss : 71.29125 epoch : 13 \n",
      "TRAIN    loss : 71.23389 epoch : 14 \n",
      "TRAIN    loss : 71.25303 epoch : 15 \n",
      "TRAIN    loss : 71.20638 epoch : 16 \n",
      "TRAIN    loss : 71.18149 epoch : 17 \n",
      "TRAIN    loss : 71.14258 epoch : 18 \n",
      "TRAIN    loss : 71.16387 epoch : 19 \n",
      "TRAIN    loss : 71.14109 epoch : 20 \n",
      "TRAIN    loss : 71.15353 epoch : 21 \n",
      "TRAIN    loss : 71.10092 epoch : 22 \n",
      "TRAIN    loss : 71.09323 epoch : 23 \n",
      "TRAIN    loss : 71.10407 epoch : 24 \n",
      "TRAIN    loss : 71.07934 epoch : 25 \n",
      "TRAIN    loss : 71.05545 epoch : 26 \n",
      "TRAIN    loss : 71.06137 epoch : 27 \n",
      "TRAIN    loss : 71.04428 epoch : 28 \n",
      "TRAIN    loss : 71.04406 epoch : 29 \n",
      "TRAIN    loss : 71.05008 epoch : 30 \n",
      "TRAIN    loss : 71.04407 epoch : 31 \n",
      "TRAIN    loss : 71.02840 epoch : 32 \n",
      "TRAIN    loss : 71.04264 epoch : 33 \n",
      "TRAIN    loss : 71.01117 epoch : 34 \n",
      "TRAIN    loss : 71.01064 epoch : 35 \n",
      "TRAIN    loss : 71.03204 epoch : 36 \n",
      "TRAIN    loss : 70.98493 epoch : 37 \n",
      "TRAIN    loss : 71.00087 epoch : 38 \n",
      "TRAIN    loss : 70.98244 epoch : 39 \n",
      "TRAIN    loss : 70.98418 epoch : 40 \n",
      "TRAIN    loss : 70.98460 epoch : 41 \n",
      "TRAIN    loss : 70.96847 epoch : 42 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2\\ipykernel_3008\\3466972808.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\meta2\\venv\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\meta2\\venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\meta2\\venv\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                    maximize=group['maximize'])\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\meta2\\venv\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Linear_model().cuda()\n",
    "Epoch = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.L1Loss()\n",
    "device = 'cuda'\n",
    "for epoch in range(Epoch):\n",
    "    train_loss = 0.\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        x = x.float().to(device)\n",
    "        y = y.float().to(device)\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "\n",
    "    print(f'TRAIN    loss : {train_loss:.5f} epoch : {epoch} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02326b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df[train_dfㅌ[\"외부온도관측치\"]!=0]\n",
    "temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47ad90cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.000000\n",
       "1         0.000000\n",
       "2         0.000000\n",
       "3         0.000000\n",
       "4         0.000000\n",
       "            ...   \n",
       "662395    0.022596\n",
       "662396    0.022596\n",
       "662397    0.023349\n",
       "662398    0.022596\n",
       "662399    0.021843\n",
       "Name: EC관측치, Length: 662400, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"CO2관측치\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f9038aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_df[\"총추정광량\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "afe6c948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_df[\"총추정광량\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6aa84f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PYTORCH_DATASET(nn.Module):\n",
    "    def __init__(self, path: list, img2weight: dict, imgs: np.array, img2data: dict,  \\\n",
    "                 transform=None):\n",
    "        super(PYTORCH_DATASET, self).__init__()\n",
    "        self.path = path\n",
    "        self.imgs = imgs\n",
    "\n",
    "        self.transform = transform\n",
    "        self.img2weight = img2weight\n",
    "        self.img2data = img2data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        before_img = self.imgs[idx]\n",
    "        img_path = self.path[idx]\n",
    "        img_path = img_path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        df_index = self.img2data[img_path]\n",
    "        df_label = self.img2weight[img_path]\n",
    "\n",
    "        after_img = self.transform(image=before_img)[\"image\"]\n",
    "\n",
    "        return {\"사진\": after_img, \"정보\": df_index, \"상표\": df_label}\n",
    "\n",
    "\n",
    "class PYTORCH_PREDICTSET(nn.Module):\n",
    "    def __init__(self, path: list,  imgs: np.array, img2data: dict, \\\n",
    "                 transform=None):\n",
    "        super(PYTORCH_PREDICTSET, self).__init__()\n",
    "        self.path = path\n",
    "        self.imgs = imgs\n",
    "\n",
    "        self.transform = transform\n",
    "        self.img2data = img2data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        before_img = self.imgs[idx]\n",
    "        img_path = self.path[idx]\n",
    "        img_path = img_path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        df_index = self.img2data[img_path]\n",
    "        after_img = self.transform(image=before_img)[\"image\"]\n",
    "        return {\"사진\": after_img, \"정보\": df_index}\n",
    "\n",
    "class PYTORCH_AUGMENTSET(nn.Module):\n",
    "    def __init__(self, aug_imgs: np.array, transform_ori = None, transform_aug=None):\n",
    "        super(PYTORCH_AUGMENTSET, self).__init__()\n",
    "        self.aug_imgs = aug_imgs\n",
    "        self.transform_ori = transform_ori\n",
    "        self.transform_aug = transform_aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.aug_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        before_img = self.aug_imgs[idx]\n",
    "        after_img = self.transform_aug(image=before_img)[\"image\"]\n",
    "        before_img = self.transform_ori(image=before_img)[\"image\"]\n",
    "        temp_data = torch.FloatTensor(torch.zeros([49, 3]))\n",
    "\n",
    "        return {\"원본\": before_img, \"확장\": after_img, \"정보\": temp_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4e6996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "\n",
    "train_mode= albu.Compose([\n",
    "    albu.RandomResizedCrop(height=image_size, width=image_size,\n",
    "                           scale=(0.25, 1.0), ratio=(0.75, 1.3333333333333333),\n",
    "                           interpolation=1, p=0.9),\n",
    "    albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1,\n",
    "                          rotate_limit=30, interpolation=1, border_mode=0, value=0, p=0.25),\n",
    "    albu.HorizontalFlip(p=0.5),\n",
    "    albu.VerticalFlip(p=0.5),\n",
    "    albu.OneOf([\n",
    "        albu.MotionBlur(p=.2),\n",
    "        albu.MedianBlur(blur_limit=3, p=0.1),\n",
    "        albu.Blur(blur_limit=3, p=0.1),\n",
    "        albu.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.4,p=0.2)\n",
    "    ], p=0.25),\n",
    "    albu.OneOf([\n",
    "        albu.CLAHE(clip_limit=2),\n",
    "        albu.Sharpen(),\n",
    "        albu.Emboss(),\n",
    "        albu.RandomBrightnessContrast(),\n",
    "    ], p=0.25),\n",
    "    albu.CoarseDropout(max_holes=8, max_height=8, max_width=8, fill_value=0, p=0.25),\n",
    "    albu.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_mode = albu.Compose([\n",
    "    #                 albu.Resize(self.image_size, self.image_size),\n",
    "    albu.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class MixerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_sequence, token_dim, channel_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_mix = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            Rearrange('b n d -> b d n'),\n",
    "            FeedForward(num_sequence, token_dim, dropout),\n",
    "            Rearrange('b d n -> b n d')\n",
    "        )\n",
    "\n",
    "        self.channel_mix = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, channel_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(channel_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.token_mix(x)\n",
    "\n",
    "        x = self.channel_mix(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MLPMixer(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.dim = 3\n",
    "        self.num_sequence = 49\n",
    "        self.token_dim = 64\n",
    "        self.channel_dim = 16\n",
    "        self.mixer_blocks = nn.ModuleList([])\n",
    "        self.depth = 1\n",
    "        for _ in range(self.depth):\n",
    "            self.mixer_blocks.append(MixerBlock(self.dim, self.num_sequence, self.token_dim, self.channel_dim, self.dropout))\n",
    "        self.layer_norm = nn.LayerNorm(self.dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for mixer_block in self.mixer_blocks:\n",
    "            x = mixer_block(x)\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class CNN_MIXER(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_MIXER, self).__init__()\n",
    "        self.model = timm.create_model(\"efficientnet_b0\", pretrained=True, \\\n",
    "                                       num_classes=1)\n",
    "        self.meta = MLPMixer(0.3)\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(1283, 256)\n",
    "        self.output = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.9)\n",
    "        self.dropout1 = nn.Dropout(0.65)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dropout3 = nn.Dropout(0)\n",
    "\n",
    "    def forward(self,  x, x2, training):\n",
    "        x = self.model.forward_features(x)\n",
    "        x = self.avg(x)\n",
    "        x = x.flatten()\n",
    "        x = x.view(-1,  1280)\n",
    "        x = self.dropout(x)\n",
    "        x2 = self.meta(x2)\n",
    "        if training:\n",
    "            c = random.choice([0, 0, 0, 1, 2, 3])\n",
    "            if c == 0:\n",
    "                pass\n",
    "            elif c == 1:\n",
    "                x2 = self.dropout1(x2)\n",
    "            elif c == 2:\n",
    "                x2 = self.dropout2(x2)\n",
    "            elif c == 3:\n",
    "                x2 = self.dropout3(x2)\n",
    "        x = torch.cat([x, x2], dim=-1)\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5cb59ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.trainer.supporters import CombinedLoader\n",
    "\n",
    "class LIGHTNING_MODEL(pl.LightningModule):\n",
    "    def __init__(self, model, train_datasest, val_dataset, augment_dataset, predict_dataset):\n",
    "        super(LIGHTNING_MODEL, self).__init__()\n",
    "        self.model = model()\n",
    "        self.train_nmae = NMAE()\n",
    "        self.valid_nmae = NMAE()\n",
    "        self.augment_dataset= augment_dataset\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.predict_dataset = predict_dataset\n",
    "        self.bestnmae = 10.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        loaders = {\"a\": DataLoader(self.train_dataset, shuffle=True, batch_size=32, num_workers=0), \\\n",
    "                   \"b\": DataLoader(self.augment_dataset, shuffle=True, batch_size=8, num_workers=0)}\n",
    "        combined_loaders = CombinedLoader(loaders, mode=\"max_size_cycle\")\n",
    "        return combined_loaders\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, shuffle=False, batch_size=32, num_workers=0)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_dataset, shuffle=False, batch_size=32, num_workers=0)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        ori_batch = train_batch[\"a\"]\n",
    "        aug_batch = train_batch[\"b\"]\n",
    "        img = ori_batch[\"사진\"]\n",
    "        data = ori_batch[\"정보\"]\n",
    "        label = ori_batch[\"상표\"]\n",
    "        \n",
    "        ori = aug_batch[\"원본\"]\n",
    "        ext = aug_batch[\"확장\"]\n",
    "        temp_data = aug_batch[\"정보\"]\n",
    "\n",
    "        pred = self.model(img, data, training=True)\n",
    "        pred = pred.view(-1)\n",
    "        label = label.view(-1)\n",
    "        \n",
    "        train_loss = nn.L1Loss()(pred, label)\n",
    "        self.log(\"train_loss\", train_loss)\n",
    "        \n",
    "        train_nmae = self.train_nmae(pred, label)\n",
    "        self.log('train_NMAE', train_nmae)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ori_out = self.model(ori, temp_data, training=False)\n",
    "            ext_out = self.model(ext, temp_data, training=False)\n",
    "        con_loss = nn.L1Loss()(ori_out, ext_out)\n",
    "        con_loss = 0.25 * con_loss \n",
    "        self.log('con_loss', con_loss)\n",
    "        loss = train_loss + con_loss\n",
    "        self.log('loss', loss)\n",
    "        return train_loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        train_nmae = self.train_nmae.compute()\n",
    "        self.log(\"epoch_train_nmae\", train_nmae)\n",
    "        self.train_nmae.reset()\n",
    "        print(f\"training nmae: {train_nmae:.4}, epoch: {self.trainer.current_epoch}\")\n",
    "        \n",
    "        \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        img = val_batch[\"사진\"]\n",
    "        data = val_batch[\"정보\"]\n",
    "        label = val_batch[\"상표\"]\n",
    "\n",
    "        pred = self.model(img, data, training=False)\n",
    "        pred = pred.view(-1)\n",
    "        label = label.view(-1)\n",
    "        loss = nn.L1Loss()(pred, label)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.valid_nmae.update(pred, label)\n",
    "        return loss\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_nmae = self.valid_nmae.compute()\n",
    "        self.log(\"val_nmae\", val_nmae)\n",
    "        ext = val_nmae.item()\n",
    "        if ext < self.bestnmae:\n",
    "            self.bestnmae = ext\n",
    "        self.valid_nmae.reset()\n",
    "        print(f\"validation nmae: {val_nmae:.4}\")\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        img = batch[\"사진\"]\n",
    "        data = batch[\"정보\"]\n",
    "        pred = self.model(img, data, training=False).unsqueeze(0)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "099dab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PYTORCH_DATASET(path=trainset_path, img2weight=img2weight, imgs=train_imgset, img2data=img2data,\\\n",
    "                                            transform=train_mode)\n",
    "\n",
    "valid_dataset = PYTORCH_DATASET(path=validset_path, img2weight=img2weight, imgs=valid_imgset, img2data=img2data,\\\n",
    "                                transform=test_mode)\n",
    "\n",
    "augment_dataset = PYTORCH_AUGMENTSET(aug_imgs=augment_imgs, transform_ori=test_mode, transform_aug=train_mode)\n",
    "\n",
    "test_dataset = PYTORCH_PREDICTSET(path=test_path, imgs=test_imgs, img2data=img2test, \\\n",
    "                        transform=test_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4804567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type               | Params\n",
      "-------------------------------------------------------\n",
      "0 | model           | CNN_MIXER          | 4.3 M \n",
      "1 | train_nmae      | NMAE               | 0     \n",
      "2 | valid_nmae      | NMAE               | 0     \n",
      "3 | augment_dataset | PYTORCH_AUGMENTSET | 0     \n",
      "4 | train_dataset   | PYTORCH_DATASET    | 0     \n",
      "5 | val_dataset     | PYTORCH_DATASET    | 0     \n",
      "6 | predict_dataset | PYTORCH_PREDICTSET | 0     \n",
      "-------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "8.689     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 1.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dc666512b34cc8bd24696d4a97f9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 1.333\n",
      "training nmae: 12.14, epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.7888\n",
      "training nmae: 40.01, epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3759\n",
      "training nmae: 26.98, epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2738\n",
      "training nmae: 15.72, epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2884\n",
      "training nmae: 9.61, epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3896\n",
      "training nmae: 14.84, epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.23\n",
      "training nmae: 9.631, epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2671\n",
      "training nmae: 20.69, epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.4115\n",
      "training nmae: 10.18, epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.376\n",
      "training nmae: 20.39, epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.4867\n",
      "training nmae: 10.23, epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.4008\n",
      "training nmae: 10.46, epoch: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3707\n",
      "training nmae: 9.893, epoch: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2357\n",
      "training nmae: 8.525, epoch: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3516\n",
      "training nmae: 6.946, epoch: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2698\n",
      "training nmae: 6.979, epoch: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3735\n",
      "training nmae: 19.04, epoch: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.4011\n",
      "training nmae: 6.156, epoch: 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3748\n",
      "training nmae: 6.925, epoch: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3607\n",
      "training nmae: 5.386, epoch: 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3174\n",
      "training nmae: 7.06, epoch: 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2475\n",
      "training nmae: 12.31, epoch: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1848\n",
      "training nmae: 6.717, epoch: 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2042\n",
      "training nmae: 6.739, epoch: 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2245\n",
      "training nmae: 6.336, epoch: 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1646\n",
      "training nmae: 5.495, epoch: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1871\n",
      "training nmae: 4.088, epoch: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1805\n",
      "training nmae: 5.898, epoch: 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1949\n",
      "training nmae: 5.108, epoch: 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1991\n",
      "training nmae: 8.336, epoch: 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1623\n",
      "training nmae: 6.841, epoch: 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.147\n",
      "training nmae: 7.125, epoch: 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2693\n",
      "training nmae: 6.592, epoch: 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1695\n",
      "training nmae: 8.131, epoch: 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2193\n",
      "training nmae: 7.631, epoch: 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.284\n",
      "training nmae: 9.312, epoch: 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3226\n",
      "training nmae: 7.771, epoch: 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.6029\n",
      "training nmae: 11.03, epoch: 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1951\n",
      "training nmae: 6.647, epoch: 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.5968\n",
      "training nmae: 6.726, epoch: 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3086\n",
      "training nmae: 8.409, epoch: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2585\n",
      "training nmae: 6.41, epoch: 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2503\n",
      "training nmae: 6.608, epoch: 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.3267\n",
      "training nmae: 9.345, epoch: 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.4029\n",
      "training nmae: 4.895, epoch: 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1686\n",
      "training nmae: 4.915, epoch: 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2111\n",
      "training nmae: 7.318, epoch: 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2\n",
      "training nmae: 6.254, epoch: 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.1689\n",
      "training nmae: 5.478, epoch: 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation nmae: 0.2035\n",
      "training nmae: 5.413, epoch: 49\n"
     ]
    }
   ],
   "source": [
    "model_name = \"efficientnet_B0\"\n",
    "\n",
    "model = LIGHTNING_MODEL(CNN_MIXER, train_dataset, valid_dataset, augment_dataset, test_dataset)\n",
    "\n",
    "check_path =  f\"D:/DACON_GROWTH/변수체크1/{model_name}\"\n",
    "if not os.path.exists(check_path):\n",
    "    os.makedirs(check_path)\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=check_path, save_top_k=1, monitor=\"val_nmae\", \\\n",
    "                                      save_weights_only=True)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    devices=[0],\n",
    "    accelerator='gpu',\n",
    "    max_epochs=50,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    precision=16\n",
    ")\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "bestscore = model.bestnmae\n",
    "checkpoint_ = os.listdir(check_path)[0]\n",
    "file_name = os.path.basename(checkpoint_).split(\".ckpt\")[0]\n",
    "src = os.path.join(check_path, checkpoint_)\n",
    "score_name = file_name + f\"_{bestscore : .4f}.ckpt\"\n",
    "dst = os.path.join(check_path, score_name)\n",
    "os.rename(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7b37743",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PYTORCH_PREDICTSET(path=test_path, imgs=test_imgs, img2data=img2test, \\\n",
    "                                    transform=test_mode)\n",
    "\n",
    "model = LIGHTNING_MODEL.load_from_checkpoint(checkpoint_path=\"D:\\DACON_GROWTH\\변수체크1\\efficientnet_B0/epoch=31-step=1984_ 0.1470.ckpt\",\n",
    "                model=  CNN_MIXER, train_datasest = None, val_dataset = None, \\\n",
    "                augment_dataset= None, predict_dataset = test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b327d6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "D:\\meta2\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:245: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc28334de754a8c92ca0f5fc0aed766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 62it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = trainer.predict(model)\n",
    "sub_list = []\n",
    "for p in prediction:\n",
    "    p = p.view(-1)\n",
    "    for sample in p:\n",
    "        sample = sample.cpu().numpy()\n",
    "        sub_list.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4e1ceda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 54.7   , 274.2   ,   6.48  ,  71.06  ,  79.56  ,  77.4   ,\n",
       "         1.577 ,  70.56  ,   1.537 ,  80.44  ,   0.644 ,  34.6   ,\n",
       "        10.49  ,  27.47  ,  11.81  ,  68.75  ,  77.25  ,  27.98  ,\n",
       "        81.06  , 269.5   ,  32.1   ,   5.492 ,   2.137 ,  14.42  ,\n",
       "        64.6   ,  73.75  , 128.1   ,  38.47  ,  80.5   ,  84.94  ,\n",
       "        75.5   ,  15.06  ,   2.525 ,   6.223 ,   8.766 , 148.6   ,\n",
       "         3.732 ,  78.94  ,   4.434 ,  31.33  ,  81.    , 113.56  ,\n",
       "         1.781 ,  26.    ,  71.4   ,  25.94  ,  69.25  ,  30.34  ,\n",
       "        67.94  ,  70.2   , 194.8   ,  65.7   ,  79.75  ,  57.75  ,\n",
       "        83.94  ,  39.22  ,  78.56  ,  23.84  ,  39.25  ,  72.5   ,\n",
       "         2.682 ,  34.66  ,  80.6   ,  87.4   ,  77.7   ,  42.53  ,\n",
       "        73.56  ,  77.7   , 121.4   ,  12.15  , 227.1   ,  85.2   ,\n",
       "        78.06  ,   2.973 ,  10.53  , 118.7   ,   1.011 ,  69.25  ,\n",
       "        67.2   ,  70.2   ,  66.8   ,  82.75  ,   8.73  ,  10.18  ,\n",
       "         2.172 ,  11.836 ,  48.25  ,  57.9   ,  67.94  ,  59.94  ,\n",
       "        81.7   ,  84.6   ,   7.355 ,  14.16  ,  22.64  ,  51.12  ,\n",
       "        34.44  ,  78.94  ,  81.2   ,   4.8   , 260.5   ,   0.599 ,\n",
       "        51.06  ,  83.06  ,   0.6924,   5.35  ,  69.3   ,  28.95  ,\n",
       "         2.38  ,   1.1875,  12.11  ,   0.7344,   4.465 ,  61.06  ,\n",
       "        71.    ,  58.9   , 196.8   ,   1.944 ,  52.47  ,   2.262 ,\n",
       "       137.5   ,  12.17  ,  38.53  ,  33.66  ,  27.8   ,  71.9   ,\n",
       "        31.44  ,  63.47  ,   0.7114,  42.56  ,  21.53  , 288.8   ,\n",
       "        28.1   , 290.5   ,  91.4   ,  41.34  ,   1.686 , 255.9   ,\n",
       "        43.7   ,  34.53  ,  51.56  ,  91.9   ,  87.56  ,   0.659 ,\n",
       "        31.16  ,  88.06  ,  18.62  ,  80.7   ,  69.4   ,   6.96  ,\n",
       "         2.55  ,  22.2   ,   6.5   ,  82.56  ,  44.97  ,  14.99  ,\n",
       "         2.736 ,  24.25  ,  75.75  ,  27.14  ,  61.5   ,   0.8193,\n",
       "         0.6865,   8.875 ,   1.058 ,   8.9   ,   4.01  ,   7.715 ,\n",
       "        12.555 ,  46.34  ,  25.36  ,  39.94  ,   4.38  ,   9.08  ,\n",
       "         3.318 ,   3.367 ,  83.56  ,  86.56  ,   9.82  ,  10.875 ,\n",
       "       181.8   ,   5.723 ,  26.08  ,  86.44  ,   2.775 , 198.8   ,\n",
       "        13.03  , 321.5   ,  21.86  ,  36.4   ,  12.13  ,  83.9   ,\n",
       "        66.3   ,  12.27  ,  77.94  ,   3.082 ,  12.875 ,  50.84  ,\n",
       "       186.    ,  45.38  ,  29.23  , 203.1   ,   1.459 ,  79.3   ,\n",
       "        16.42  ,  45.88  ,  76.25  ,   2.994 ,   4.21  ,  50.78  ,\n",
       "        27.16  ,   0.6978,   4.027 ,   8.164 ,  43.2   ,  44.    ,\n",
       "        46.4   ,   5.27  ,  66.44  ,  82.44  ,  13.195 , 116.8   ,\n",
       "        36.9   ,  70.9   ,   5.55  ,  84.8   ,  25.97  ,  61.5   ,\n",
       "        37.84  ,  11.555 ,  84.44  ,   8.17  ,  28.06  , 286.    ,\n",
       "        61.4   ,  96.3   ,   5.793 ,   2.46  ,   1.217 ,   5.38  ,\n",
       "       209.1   ,   6.87  ,  25.25  ,   2.309 ,  60.62  ,   4.785 ,\n",
       "        51.9   ,  83.4   ,   8.94  ,  45.7   ,  10.7   ,  55.38  ,\n",
       "         8.414 ,  56.4   ,  22.56  ,  54.3   ,  54.12  ,  47.4   ,\n",
       "        38.66  ,   1.444 ,  65.8   ,  83.56  ,  82.3   ,  48.7   ,\n",
       "        32.28  ,  14.16  ,  32.03  ,   2.352 ,   0.6953,  79.2   ,\n",
       "       103.94  ,  63.62  ,  73.9   ,  84.    ,  16.28  , 203.6   ,\n",
       "         8.34  ,   3.104 ,   0.8735, 317.8   ,  26.45  ,   6.832 ,\n",
       "         9.26  ,   3.6   , 171.5   ,  59.8   , 150.5   , 169.4   ,\n",
       "         7.43  ,   5.75  ,  52.25  ,  24.64  ,   4.76  ,   9.08  ,\n",
       "        10.07  ,  77.44  ,   3.797 ,   8.305 ,   0.7754,  73.06  ,\n",
       "        25.22  ,   0.678 ,  69.7   ,   4.37  ,  72.3   ,   5.996 ,\n",
       "        33.5   ,   6.613 ,  19.95  ,  66.5   , 311.2   ,  28.17  ,\n",
       "       172.9   , 168.6   ,   1.285 ,  25.22  ,   2.895 , 122.8   ,\n",
       "        86.25  ,  79.9   ,  38.28  ,  71.8   ,   0.8496,   2.225 ,\n",
       "        81.    ,  34.56  , 106.1   ,  67.94  ,  25.27  ,  87.7   ,\n",
       "         0.674 ,   0.7256, 147.8   , 205.1   ,   9.08  ,  26.55  ,\n",
       "         6.234 ,   8.586 ,  69.94  ,  52.56  ,  22.7   ,   3.023 ,\n",
       "        84.3   ,  81.2   ,  66.56  , 263.    ,  13.375 ,   0.8633,\n",
       "       299.2   ,  10.23  ,   2.104 ,  83.2   ,  15.836 ,  15.91  ,\n",
       "         7.19  ,  40.03  ,  32.34  ,  23.    ,   4.85  ,  67.9   ,\n",
       "        87.8   , 176.5   ,  29.53  ,   9.67  ,  28.9   , 249.2   ,\n",
       "       236.6   ,  13.98  ,  31.03  ,  56.78  ,  75.2   ,   4.074 ,\n",
       "        66.25  , 264.    , 144.8   , 162.    ,  68.5   ,   3.234 ,\n",
       "        99.    ,  24.7   ,   0.679 ,  50.53  ,  10.65  ,   3.977 ,\n",
       "       274.5   ,  65.1   ,   1.857 ,   1.526 ,  70.25  ,   2.521 ,\n",
       "        21.19  ,  55.2   ,  11.87  , 176.6   ,  77.94  ,  64.1   ,\n",
       "        24.42  ,  71.8   ,   4.777 ,  67.8   ,  15.24  ,  83.3   ,\n",
       "         8.625 ,  46.16  ,  53.75  ,  44.97  ,  27.05  ,  65.75  ,\n",
       "         5.69  ,  38.25  ,  66.6   ,  18.78  , 315.8   ,   0.9307,\n",
       "         9.37  , 310.8   ,  32.34  ,   0.7373,  40.94  ,  30.94  ,\n",
       "       232.8   ,   9.89  ,  11.55  ,  52.9   ,  69.    ,  77.5   ,\n",
       "        27.7   ,  78.75  ,   7.09  ,   3.865 ,  66.56  ,   2.88  ,\n",
       "        85.2   , 142.6   ,  25.2   ,  63.75  ,   0.695 ,  78.8   ,\n",
       "        80.8   ,  35.56  ,  87.1   ,   7.402 ,  83.9   ,  22.95  ,\n",
       "        34.4   ,   4.734 ,   6.766 ,   5.844 ,   1.717 ,  27.47  ,\n",
       "         9.13  ,   1.672 , 305.8   ,   0.8677,  76.3   ,  62.44  ,\n",
       "        81.5   ,  25.77  ,  48.38  , 245.    ], dtype=float16)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sub_list) * 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5577063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"D:/DACON_GROWTH/sample_submission.csv\")\n",
    "sample_submission[\"leaf_weight\"] = np.array(sub_list) * 0.87\n",
    "sample_submission.to_csv(\"D:/DACON_GROWTH/prediction_collection/negative_mixer.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6c7982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>leaf_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>67.051250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>288.332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>6.248164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>73.174375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>87.785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>456.png</td>\n",
       "      <td>73.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>457.png</td>\n",
       "      <td>87.845625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>458.png</td>\n",
       "      <td>30.691406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>459.png</td>\n",
       "      <td>55.987187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>460.png</td>\n",
       "      <td>232.678750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    img_name  leaf_weight\n",
       "0    001.png    67.051250\n",
       "1    002.png   288.332500\n",
       "2    003.png     6.248164\n",
       "3    004.png    73.174375\n",
       "4    005.png    87.785000\n",
       "..       ...          ...\n",
       "455  456.png    73.720000\n",
       "456  457.png    87.845625\n",
       "457  458.png    30.691406\n",
       "458  459.png    55.987187\n",
       "459  460.png   232.678750\n",
       "\n",
       "[460 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff0mixer = pd.read_csv(\"D:/DACON_GROWTH/prediction_collection/eff03featuremixer.csv\")\n",
    "eff0mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb9dc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_nmae(y_true, y_pred):\n",
    "    result = np.mean(np.abs(y_true-y_pred)) / np.mean(np.abs(y_true))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f962fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07515053752849575"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_nmae(best_submission[\"leaf_weight\"], np.array(sub_list)*0.87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "affceba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07202574694711976"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_nmae(best_submission[\"leaf_weight\"], eff0mixer[\"leaf_weight\"]*0.91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60be4068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>leaf_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>56.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>300.578750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>4.577187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>67.930312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>76.690625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>456.png</td>\n",
       "      <td>63.929063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>457.png</td>\n",
       "      <td>77.781875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>458.png</td>\n",
       "      <td>29.350078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>459.png</td>\n",
       "      <td>48.681875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>460.png</td>\n",
       "      <td>234.861250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    img_name  leaf_weight\n",
       "0    001.png    56.260000\n",
       "1    002.png   300.578750\n",
       "2    003.png     4.577187\n",
       "3    004.png    67.930312\n",
       "4    005.png    76.690625\n",
       "..       ...          ...\n",
       "455  456.png    63.929063\n",
       "456  457.png    77.781875\n",
       "457  458.png    29.350078\n",
       "458  459.png    48.681875\n",
       "459  460.png   234.861250\n",
       "\n",
       "[460 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_submission = pd.read_csv(\"D:/DACON_GROWTH/prediction_collection/effV2_eff0_negative_ensemble.csv\")\n",
    "best_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c515cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>leaf_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>67.05125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>288.3325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>6.248164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>73.174375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>87.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>456.png</td>\n",
       "      <td>73.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>457.png</td>\n",
       "      <td>87.845625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>458.png</td>\n",
       "      <td>30.691406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>459.png</td>\n",
       "      <td>55.987187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>460.png</td>\n",
       "      <td>232.67875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    img_name leaf_weight\n",
       "0    001.png    67.05125\n",
       "1    002.png    288.3325\n",
       "2    003.png    6.248164\n",
       "3    004.png   73.174375\n",
       "4    005.png      87.785\n",
       "..       ...         ...\n",
       "455  456.png       73.72\n",
       "456  457.png   87.845625\n",
       "457  458.png   30.691406\n",
       "458  459.png   55.987187\n",
       "459  460.png   232.67875\n",
       "\n",
       "[460 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c742b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"D:/DACON_GROWTH/prediction_collection/eff03featuremixer.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
